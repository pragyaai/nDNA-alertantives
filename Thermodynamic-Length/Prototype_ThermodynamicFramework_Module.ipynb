{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### THERMODYNAMIC LENGTH ANALYSIS - Parallel Transport on Hidden States (Leviâ€“Civitaâ€“style Continuousâ€“Depth Surrogate)"
      ],
      "metadata": {
        "id": "t9a5Ff-Zm777"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4dyKS2m4ebN"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets plotly torch\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class UnifiedThermodynamicFramework:\n",
        "    \"\"\"\n",
        "    Implements Method 2 (Spectral Curvature) + Method 5 (Belief Vectors)\n",
        "    from NDNA Alternative paper with Spinal thermodynamic length\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"ðŸš€ Unified Framework | Device: {self.device}\")\n",
        "\n",
        "    def load_model(self, model_name):\n",
        "        \"\"\"Load model efficiently\"\"\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float32,  # Changed from torch.float16 to torch.float32\n",
        "            device_map=\"auto\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "        return model, tokenizer\n",
        "\n",
        "    def compute_spectral_curvature(self, layer_output):\n",
        "        \"\"\"\n",
        "        Method 2: Spectral Curvature (Page 5-6)\n",
        "        Îº_spectral = trace(H) / ||H||_F where H is Hessian approximation\n",
        "        \"\"\"\n",
        "        # Compute covariance as Hessian approximation\n",
        "        H = torch.cov(layer_output.T)\n",
        "\n",
        "        # Spectral curvature components\n",
        "        trace_H = torch.trace(H).item()\n",
        "        frobenius_norm = torch.norm(H, p='fro').item()\n",
        "\n",
        "        spectral_curvature = trace_H / (frobenius_norm + 1e-8)\n",
        "\n",
        "        # Eigenvalue analysis for curvature direction\n",
        "        eigenvalues = torch.linalg.eigvalsh(H).cpu().numpy()\n",
        "\n",
        "        return {\n",
        "            'curvature': spectral_curvature,\n",
        "            'trace': trace_H,\n",
        "            'frobenius': frobenius_norm,\n",
        "            'eigenvalues': eigenvalues,\n",
        "            'condition_number': np.max(np.abs(eigenvalues)) / (np.min(np.abs(eigenvalues)) + 1e-10)\n",
        "        }\n",
        "\n",
        "    def compute_belief_vector(self, layer_output, next_layer_output):\n",
        "        \"\"\"\n",
        "        Method 5: Belief Vector Evolution (Page 5-6)\n",
        "        b_t = softmax(W_t h_t) where h_t is hidden state\n",
        "        \"\"\"\n",
        "        # Compute belief transformation\n",
        "        delta_h = next_layer_output - layer_output\n",
        "\n",
        "        # Belief vector as normalized probability distribution\n",
        "        belief_logits = torch.mean(delta_h, dim=-1)\n",
        "        belief_vector = torch.softmax(belief_logits, dim=-1)\n",
        "\n",
        "        # Belief entropy and divergence\n",
        "        entropy = -torch.sum(belief_vector * torch.log(belief_vector + 1e-10)).item()\n",
        "\n",
        "        return {\n",
        "            'belief_vector': belief_vector.cpu().numpy(),\n",
        "            'entropy': entropy,\n",
        "            'concentration': torch.max(belief_vector).item()\n",
        "        }\n",
        "\n",
        "    def compute_thermodynamic_length(self, curvatures):\n",
        "        \"\"\"\n",
        "        Thermodynamic Length: L = âˆ«âˆš(g_Î¼Î½ dx^Î¼ dx^Î½)\n",
        "        Using Fisher-Rao metric from spectral curvatures\n",
        "        \"\"\"\n",
        "        length = 0.0\n",
        "        for i in range(1, len(curvatures)):\n",
        "            # Fisher-Rao distance between consecutive curvature states\n",
        "            Îº1, Îº2 = curvatures[i-1], curvatures[i]\n",
        "\n",
        "            # Arccosine distance for positive definite metrics\n",
        "            distance = 2.0 * np.arccos(np.clip(\n",
        "                np.sqrt(Îº1 * Îº2) / (Îº1 + Îº2 + 1e-8), 0, 1\n",
        "            ))\n",
        "            length += distance\n",
        "\n",
        "        return length\n",
        "\n",
        "    def analyze_model(self, model, tokenizer, texts, model_name):\n",
        "        \"\"\"Unified analysis combining Methods 2 & 5\"\"\"\n",
        "        print(f\"\\nðŸ”¬ Analyzing {model_name}...\")\n",
        "\n",
        "        num_layers = len(model.transformer.h)\n",
        "        results = {\n",
        "            'spectral_curvatures': [],\n",
        "            'belief_entropies': [],\n",
        "            'condition_numbers': [],\n",
        "            'thermodynamic_contributions': []\n",
        "        }\n",
        "\n",
        "        # Process texts through model\n",
        "        for text in texts[:3]:  # Limited for GPU efficiency\n",
        "            tokens = tokenizer(text, return_tensors=\"pt\", max_length=128,\n",
        "                             truncation=True, padding=True).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**tokens, output_hidden_states=True)\n",
        "                hidden_states = outputs.hidden_states\n",
        "\n",
        "            # Analyze each layer\n",
        "            for i in range(num_layers):\n",
        "                h_t = hidden_states[i].squeeze(0)\n",
        "\n",
        "                # Method 2: Spectral Curvature\n",
        "                spectral = self.compute_spectral_curvature(h_t)\n",
        "                results['spectral_curvatures'].append(spectral['curvature'])\n",
        "                results['condition_numbers'].append(spectral['condition_number'])\n",
        "\n",
        "                # Method 5: Belief Vector (if next layer exists)\n",
        "                if i < num_layers - 1:\n",
        "                    h_next = hidden_states[i+1].squeeze(0)\n",
        "                    belief = self.compute_belief_vector(h_t, h_next)\n",
        "                    results['belief_entropies'].append(belief['entropy'])\n",
        "\n",
        "        # Average across texts\n",
        "        results['spectral_curvatures'] = np.mean(\n",
        "            np.array(results['spectral_curvatures']).reshape(-1, num_layers), axis=0\n",
        "        )\n",
        "        results['condition_numbers'] = np.mean(\n",
        "            np.array(results['condition_numbers']).reshape(-1, num_layers), axis=0\n",
        "        )\n",
        "        results['belief_entropies'] = np.mean(\n",
        "            np.array(results['belief_entropies']).reshape(-1, num_layers-1), axis=0\n",
        "        )\n",
        "\n",
        "\n",
        "        # Compute thermodynamic length\n",
        "        results['thermodynamic_length'] = self.compute_thermodynamic_length(\n",
        "            results['spectral_curvatures']\n",
        "        )\n",
        "\n",
        "        # Normalize spectral curvatures to 1-100 scale\n",
        "        Îº = results['spectral_curvatures']\n",
        "        results['normalized_curvature'] = 1 + 99 * (Îº - Îº.min()) / (Îº.max() - Îº.min() + 1e-8)\n",
        "\n",
        "        print(f\"âœ… {model_name}: Length={results['thermodynamic_length']:.6f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def create_unified_plot(self, llama_results, gpt_results):\n",
        "        \"\"\"Unified 3D visualization\"\"\"\n",
        "        print(\"\\nðŸŽ¨ Creating Unified 3D Plot...\")\n",
        "\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            specs=[\n",
        "                [{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}],\n",
        "                [{\"type\": \"surface\"}, {\"type\": \"scatter\"}]\n",
        "            ],\n",
        "            subplot_titles=[\n",
        "                'Spectral Curvature (Method 2)',\n",
        "                'Belief Entropy (Method 5)',\n",
        "                'Combined Surface',\n",
        "                'Thermodynamic Length'\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Plot 1: Spectral Curvature\n",
        "        llama_layers = np.arange(len(llama_results['normalized_curvature']))\n",
        "        gpt_layers = np.arange(len(gpt_results['normalized_curvature']))\n",
        "\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=llama_layers, y=np.zeros_like(llama_layers),\n",
        "            z=llama_results['normalized_curvature'],\n",
        "            mode='lines+markers', line=dict(color='blue', width=5),\n",
        "            marker=dict(size=8, color=llama_results['normalized_curvature'],\n",
        "                       colorscale='Blues'),\n",
        "            name='Llama Curvature'\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=gpt_layers, y=np.ones_like(gpt_layers),\n",
        "            z=gpt_results['normalized_curvature'],\n",
        "            mode='lines+markers', line=dict(color='red', width=5),\n",
        "            marker=dict(size=8, color=gpt_results['normalized_curvature'],\n",
        "                       colorscale='Reds'),\n",
        "            name='GPT Curvature'\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        # Update axis labels for Plot 1\n",
        "        fig.update_layout(\n",
        "            scene1 = dict(\n",
        "                xaxis_title='Layer Number',\n",
        "                yaxis_title='Model (0: Llama, 1: GPT-2)',\n",
        "                zaxis_title='Normalized Spectral Curvature'\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # Plot 2: Belief Entropy\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=np.arange(len(llama_results['belief_entropies'])),\n",
        "            y=np.zeros(len(llama_results['belief_entropies'])),\n",
        "            z=llama_results['belief_entropies'],\n",
        "            mode='markers', marker=dict(size=6, color='cyan'),\n",
        "            name='Llama Belief'\n",
        "        ), row=1, col=2)\n",
        "\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=np.arange(len(gpt_results['belief_entropies'])),\n",
        "            y=np.ones(len(gpt_results['belief_entropies'])),\n",
        "            z=gpt_results['belief_entropies'],\n",
        "            mode='markers', marker=dict(size=6, color='orange'),\n",
        "            name='GPT Belief'\n",
        "        ), row=1, col=2)\n",
        "\n",
        "        # Update axis labels for Plot 2\n",
        "        fig.update_layout(\n",
        "             scene2 = dict(\n",
        "                xaxis_title='Layer Number',\n",
        "                yaxis_title='Model (0: Llama, 1: GPT-2)',\n",
        "                zaxis_title='Belief Entropy'\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # Plot 3: Surface\n",
        "        max_len = max(len(llama_results['normalized_curvature']),\n",
        "                      len(gpt_results['normalized_curvature']))\n",
        "        llama_pad = np.pad(llama_results['normalized_curvature'],\n",
        "                           (0, max_len - len(llama_results['normalized_curvature'])),\n",
        "                           mode='edge')\n",
        "        gpt_pad = np.pad(gpt_results['normalized_curvature'],\n",
        "                         (0, max_len - len(gpt_results['normalized_curvature'])),\n",
        "                         mode='edge')\n",
        "\n",
        "        surface_data = np.array([llama_pad, gpt_pad])\n",
        "        layer_grid, model_grid = np.meshgrid(np.arange(max_len), [0, 1])\n",
        "\n",
        "        fig.add_trace(go.Surface(\n",
        "            x=layer_grid, y=model_grid, z=surface_data,\n",
        "            colorscale='Viridis', opacity=0.8\n",
        "        ), row=2, col=1)\n",
        "\n",
        "         # Update axis labels for Plot 3\n",
        "        fig.update_layout(\n",
        "            scene3 = dict(\n",
        "                xaxis_title='Layer Number',\n",
        "                yaxis_title='Model (0: Llama, 1: GPT-2)',\n",
        "                zaxis_title='Normalized Spectral Curvature'\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # Plot 4: Length comparison\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=['Llama', 'GPT-2'],\n",
        "            y=[llama_results['thermodynamic_length'],\n",
        "               gpt_results['thermodynamic_length']],\n",
        "            marker_color=['blue', 'red']\n",
        "        ), row=2, col=2)\n",
        "\n",
        "        # Update axis labels for Plot 4\n",
        "        fig.update_layout(\n",
        "            xaxis4=dict(title='Model'),\n",
        "            yaxis4=dict(title='Thermodynamic Length')\n",
        "        )\n",
        "\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Unified Thermodynamic Framework: Methods 2 & 5',\n",
        "            height=1000, width=1400, showlegend=True\n",
        "        )\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "        return fig\n",
        "\n",
        "def run_unified_analysis():\n",
        "    \"\"\"Main execution\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"UNIFIED THERMODYNAMIC FRAMEWORK\")\n",
        "    print(\"Method 2: Spectral Curvature | Method 5: Belief Vectors\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize\n",
        "    framework = UnifiedThermodynamicFramework()\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"\\nðŸ“š Loading SQuAD...\")\n",
        "    dataset = load_dataset(\"squad\", split=\"validation[:20]\")\n",
        "    texts = [f\"Context: {d['context'][:200]} Q: {d['question']}\"\n",
        "             for d in dataset]\n",
        "\n",
        "    # Load models\n",
        "    print(\"\\nðŸ“¥ Loading Models...\")\n",
        "    llama_model, llama_tok = framework.load_model(\"gpt2\")  # Proxy\n",
        "    gpt_model, gpt_tok = framework.load_model(\"gpt2-large\")\n",
        "\n",
        "    # Analyze\n",
        "    llama_results = framework.analyze_model(llama_model, llama_tok, texts, \"Llama\")\n",
        "    gpt_results = framework.analyze_model(gpt_model, gpt_tok, texts, \"GPT-2\")\n",
        "\n",
        "    # Visualize\n",
        "    fig = framework.create_unified_plot(llama_results, gpt_results)\n",
        "\n",
        "    # Summary\n",
        "    print(f\"\\nðŸ† RESULTS:\")\n",
        "    print(f\"Llama Length: {llama_results['thermodynamic_length']:.6f}\")\n",
        "    print(f\"GPT-2 Length: {gpt_results['thermodynamic_length']:.6f}\")\n",
        "    print(f\"Winner: {'GPT-2' if gpt_results['thermodynamic_length'] > llama_results['thermodynamic_length'] else 'Llama'}\")\n",
        "\n",
        "    return {'llama': llama_results, 'gpt': gpt_results, 'fig': fig}\n",
        "\n",
        "# Execute\n",
        "results = run_unified_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spectral Curvature-based Thermodynamic Length Prototype"
      ],
      "metadata": {
        "id": "6D82fNpNeQp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets plotly torch accelerate\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ThermodynamicLengthAnalyzer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"ðŸš€ Thermodynamic Length Analyzer | Device: {self.device}\")\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Load Llama-3.2 and GPT-2 Large without quantization\"\"\"\n",
        "        print(\"\\nðŸ“¥ Loading Models...\")\n",
        "\n",
        "        models = {}\n",
        "\n",
        "        # Llama-3.2-3B (or proxy)\n",
        "        try:\n",
        "            models['llama_tok'] = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
        "            models['llama_tok'].pad_token = models['llama_tok'].eos_token\n",
        "            models['llama'] = AutoModelForCausalLM.from_pretrained(\n",
        "                \"meta-llama/Llama-3.2-3B\",\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                low_cpu_mem_usage=True,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            print(\"âœ… Llama-3.2-3B loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸  Llama-3.2 not available: {e}\")\n",
        "            print(\"   Loading proxy: gpt2-medium\")\n",
        "            models['llama_tok'] = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
        "            models['llama_tok'].pad_token = models['llama_tok'].eos_token\n",
        "            models['llama'] = AutoModelForCausalLM.from_pretrained(\n",
        "                \"gpt2-medium\",\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "            print(\"âœ… Llama proxy (gpt2-medium) loaded\")\n",
        "\n",
        "        # GPT-2 Large\n",
        "        models['gpt_tok'] = AutoTokenizer.from_pretrained(\"gpt2-large\")\n",
        "        models['gpt_tok'].pad_token = models['gpt_tok'].eos_token\n",
        "        models['gpt'] = AutoModelForCausalLM.from_pretrained(\n",
        "            \"gpt2-large\",\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "        print(\"âœ… GPT-2 Large loaded\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        return models\n",
        "\n",
        "    def load_squad_v2(self):\n",
        "        \"\"\"Load SQuAD 2.0 dataset\"\"\"\n",
        "        print(\"\\nðŸ“š Loading SQuAD 2.0...\")\n",
        "        dataset = load_dataset(\"squad_v2\", split=\"validation\")\n",
        "\n",
        "        samples = []\n",
        "        for i, item in enumerate(dataset):\n",
        "            if i >= 20:\n",
        "                break\n",
        "\n",
        "            context = item['context'][:300]\n",
        "            question = item['question']\n",
        "            answers = item['answers']['text']\n",
        "\n",
        "            text = f\"Context: {context}\\nQuestion: {question}\\nAnswer: {answers[0] if answers else 'No answer'}\"\n",
        "            samples.append({'text': text, 'answerable': len(answers) > 0})\n",
        "\n",
        "        print(f\"âœ… {len(samples)} samples loaded\")\n",
        "        return samples\n",
        "\n",
        "    def compute_spectral_curvature_accurate(self, hidden_state):\n",
        "        \"\"\"\n",
        "        Accurate Method 2: Spectral Curvature\n",
        "        Îº_spectral = Tr(H) / ||H||_F\n",
        "        \"\"\"\n",
        "        # Compute Hessian approximation via covariance\n",
        "        if hidden_state.dim() == 3:\n",
        "            hidden_state = hidden_state.squeeze(0)\n",
        "\n",
        "        # Center the data\n",
        "        H_centered = hidden_state - hidden_state.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # Covariance matrix as Hessian approximation\n",
        "        H = torch.matmul(H_centered.T, H_centered) / (H_centered.shape[0] - 1)\n",
        "\n",
        "        # Spectral curvature components\n",
        "        trace = torch.trace(H).item()\n",
        "        frobenius = torch.norm(H, p='fro').item()\n",
        "\n",
        "        spectral_curvature = trace / (frobenius + 1e-10)\n",
        "\n",
        "        # Eigenvalue decomposition for detailed analysis\n",
        "        try:\n",
        "            eigenvalues, eigenvectors = torch.linalg.eigh(H)\n",
        "            eigenvalues = eigenvalues.cpu().numpy()\n",
        "\n",
        "            # Spectral properties\n",
        "            max_eigenval = np.max(eigenvalues)\n",
        "            min_eigenval = np.min(eigenvalues[eigenvalues > 1e-10])\n",
        "            condition_number = max_eigenval / min_eigenval if min_eigenval > 0 else 1e10\n",
        "            spectral_gap = max_eigenval - eigenvalues[-2] if len(eigenvalues) > 1 else 0\n",
        "\n",
        "        except:\n",
        "            eigenvalues = np.array([1.0])\n",
        "            condition_number = 1.0\n",
        "            spectral_gap = 0.0\n",
        "\n",
        "        return {\n",
        "            'curvature': spectral_curvature,\n",
        "            'trace': trace,\n",
        "            'frobenius': frobenius,\n",
        "            'eigenvalues': eigenvalues,\n",
        "            'condition_number': condition_number,\n",
        "            'spectral_gap': spectral_gap\n",
        "        }\n",
        "\n",
        "    def compute_thermodynamic_length_accurate(self, curvatures):\n",
        "        \"\"\"\n",
        "        Accurate Thermodynamic Length using Fisher-Rao metric\n",
        "        L = Î£ d(Îº_i, Îº_{i+1}) where d is Fisher-Rao distance\n",
        "        \"\"\"\n",
        "        if len(curvatures) < 2:\n",
        "            return {'total_length': 0.0, 'layer_contributions': np.array([0.0]), 'cumulative_length': np.array([0.0])}\n",
        "\n",
        "        total_length = 0.0\n",
        "        layer_contributions = []\n",
        "\n",
        "        for i in range(1, len(curvatures)):\n",
        "            Îº_prev = max(curvatures[i-1], 1e-10)\n",
        "            Îº_curr = max(curvatures[i], 1e-10)\n",
        "\n",
        "            # Fisher-Rao distance for positive scalar parameters\n",
        "            # d_FR(Îº1, Îº2) = 2 * arccos(sqrt(Îº1 * Îº2) / (Îº1 + Îº2))\n",
        "            sqrt_product = np.sqrt(Îº_prev * Îº_curr)\n",
        "            sum_params = Îº_prev + Îº_curr\n",
        "\n",
        "            ratio = np.clip(sqrt_product / sum_params, 0, 1)\n",
        "            fisher_rao_distance = 2.0 * np.arccos(ratio)\n",
        "\n",
        "            total_length += fisher_rao_distance\n",
        "            layer_contributions.append(fisher_rao_distance)\n",
        "\n",
        "        layer_contributions = np.array([0.0] + layer_contributions)\n",
        "        cumulative_length = np.cumsum(layer_contributions)\n",
        "\n",
        "        return {\n",
        "            'total_length': total_length,\n",
        "            'layer_contributions': layer_contributions,\n",
        "            'cumulative_length': cumulative_length\n",
        "        }\n",
        "\n",
        "    def analyze_model_complete(self, model, tokenizer, samples, model_name):\n",
        "        \"\"\"Complete thermodynamic analysis\"\"\"\n",
        "        print(f\"\\nðŸ”¬ Analyzing {model_name}...\")\n",
        "\n",
        "        # Determine the number of layers based on model type\n",
        "        if hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
        "            num_layers = len(model.transformer.h)\n",
        "            hidden_states_attr = model.transformer.h\n",
        "        elif hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
        "            num_layers = len(model.model.layers)\n",
        "            hidden_states_attr = model.model.layers\n",
        "        else:\n",
        "            raise AttributeError(f\"Could not find layers for model type {type(model).__name__}\")\n",
        "\n",
        "        print(f\"   Number of layers: {num_layers}\")\n",
        "\n",
        "        # Storage for metrics\n",
        "        all_curvatures = []\n",
        "        all_traces = []\n",
        "        all_eigenvalues = []\n",
        "        all_conditions = []\n",
        "        all_spectral_gaps = []\n",
        "\n",
        "        # Process samples\n",
        "        for idx, sample in enumerate(samples[:8]):\n",
        "            tokens = tokenizer(\n",
        "                sample['text'],\n",
        "                return_tensors=\"pt\",\n",
        "                max_length=256,\n",
        "                truncation=True,\n",
        "                padding=True\n",
        "            ).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**tokens, output_hidden_states=True)\n",
        "                hidden_states = outputs.hidden_states\n",
        "\n",
        "            sample_curvatures = []\n",
        "            sample_traces = []\n",
        "            sample_conditions = []\n",
        "            sample_gaps = []\n",
        "\n",
        "            for layer_idx in range(num_layers):\n",
        "                hidden = hidden_states[layer_idx]\n",
        "\n",
        "                spectral = self.compute_spectral_curvature_accurate(hidden)\n",
        "\n",
        "                sample_curvatures.append(spectral['curvature'])\n",
        "                sample_traces.append(spectral['trace'])\n",
        "                sample_conditions.append(spectral['condition_number'])\n",
        "                sample_gaps.append(spectral['spectral_gap'])\n",
        "\n",
        "                if idx == 0:  # Store eigenvalues from first sample\n",
        "                    all_eigenvalues.append(spectral['eigenvalues'])\n",
        "\n",
        "            all_curvatures.append(sample_curvatures)\n",
        "            all_traces.append(sample_traces)\n",
        "            all_conditions.append(sample_conditions)\n",
        "            all_spectral_gaps.append(sample_gaps)\n",
        "\n",
        "            if (idx + 1) % 3 == 0:\n",
        "                print(f\"   Processed {idx + 1}/{len(samples[:8])} samples\")\n",
        "\n",
        "        # Average across samples\n",
        "        curvatures = np.mean(all_curvatures, axis=0)\n",
        "        traces = np.mean(all_traces, axis=0)\n",
        "        conditions = np.mean(all_conditions, axis=0)\n",
        "        spectral_gaps = np.mean(all_spectral_gaps, axis=0)\n",
        "\n",
        "        # Compute thermodynamic length\n",
        "        thermo_results = self.compute_thermodynamic_length_accurate(curvatures)\n",
        "\n",
        "        print(f\"   âœ… Thermodynamic Length: {thermo_results['total_length']:.6f}\")\n",
        "\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'num_layers': num_layers,\n",
        "            'curvatures': curvatures,\n",
        "            'traces': traces,\n",
        "            'conditions': conditions,\n",
        "            'spectral_gaps': spectral_gaps,\n",
        "            'eigenvalues': all_eigenvalues,\n",
        "            'total_length': thermo_results['total_length'],\n",
        "            'layer_contributions': thermo_results['layer_contributions'],\n",
        "            'cumulative_length': thermo_results['cumulative_length']\n",
        "        }\n",
        "\n",
        "    def create_publication_quality_plots(self, llama_results, gpt_results):\n",
        "        \"\"\"Create publication-quality annotated plots\"\"\"\n",
        "        print(\"\\nðŸŽ¨ Creating Publication-Quality Plots...\")\n",
        "\n",
        "        # Create comprehensive figure\n",
        "        fig = make_subplots(\n",
        "            rows=3, cols=2,\n",
        "            specs=[\n",
        "                [{\"type\": \"scatter3d\", \"colspan\": 2}, None],\n",
        "                [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
        "                [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]\n",
        "            ],\n",
        "            subplot_titles=[\n",
        "                '<b>3D Thermodynamic Landscape: Layer Depth vs Spectral Curvature</b>',\n",
        "                '<b>Cumulative Thermodynamic Length by Layer</b>',\n",
        "                '<b>Layer-wise Spectral Curvature Evolution</b>',\n",
        "                '<b>Layer Contribution to Thermodynamic Length</b>',\n",
        "                '<b>Model Comparison: Total Thermodynamic Length</b>'\n",
        "            ],\n",
        "            vertical_spacing=0.12,\n",
        "            horizontal_spacing=0.15,\n",
        "            row_heights=[0.5, 0.25, 0.25]\n",
        "        )\n",
        "\n",
        "        # ==== PLOT 1: 3D Interactive Surface ====\n",
        "        llama_layers = np.arange(llama_results['num_layers'])\n",
        "        gpt_layers = np.arange(gpt_results['num_layers'])\n",
        "\n",
        "        # Llama trajectory\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=llama_layers,\n",
        "            y=llama_results['curvatures'],\n",
        "            z=llama_results['cumulative_length'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='blue', width=8),\n",
        "            marker=dict(\n",
        "                size=10,\n",
        "                color=llama_results['cumulative_length'],\n",
        "                colorscale='Blues',\n",
        "                showscale=True,\n",
        "                colorbar=dict(\n",
        "                    title=\"Cumulative<br>Length\",\n",
        "                    x=1.05,\n",
        "                    len=0.3,\n",
        "                    y=0.85\n",
        "                )\n",
        "            ),\n",
        "            name=f'Llama-3.2 ({llama_results[\"num_layers\"]} layers)',\n",
        "            hovertemplate=(\n",
        "                '<b>Llama-3.2</b><br>' +\n",
        "                'Layer Depth: %{x}<br>' +\n",
        "                'Spectral Curvature: %{y:.4f}<br>' +\n",
        "                'Cumulative Length: %{z:.4f}<br>' +\n",
        "                '<extra></extra>'\n",
        "            )\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        # GPT trajectory\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=gpt_layers,\n",
        "            y=gpt_results['curvatures'],\n",
        "            z=gpt_results['cumulative_length'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='red', width=8),\n",
        "            marker=dict(\n",
        "                size=10,\n",
        "                color=gpt_results['cumulative_length'],\n",
        "                colorscale='Reds',\n",
        "                showscale=True,\n",
        "                colorbar=dict(\n",
        "                    title=\"Cumulative<br>Length\",\n",
        "                    x=1.12,\n",
        "                    len=0.3,\n",
        "                    y=0.85\n",
        "                )\n",
        "            ),\n",
        "            name=f'GPT-2 Large ({gpt_results[\"num_layers\"]} layers)',\n",
        "            hovertemplate=(\n",
        "                '<b>GPT-2 Large</b><br>' +\n",
        "                'Layer Depth: %{x}<br>' +\n",
        "                'Spectral Curvature: %{y:.4f}<br>' +\n",
        "                'Cumulative Length: %{z:.4f}<br>' +\n",
        "                '<extra></extra>'\n",
        "            )\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        # Add connecting surface\n",
        "        max_layers = max(llama_results['num_layers'], gpt_results['num_layers'])\n",
        "\n",
        "        # Create interpolated grid for surface\n",
        "        layer_range = np.linspace(0, max_layers-1, 50)\n",
        "        model_range = np.linspace(0, 1, 30)\n",
        "\n",
        "        layer_grid, model_grid = np.meshgrid(layer_range, model_range)\n",
        "\n",
        "        # Interpolate curvatures\n",
        "        llama_interp = np.interp(layer_range, llama_layers, llama_results['curvatures'])\n",
        "        gpt_interp = np.interp(layer_range, gpt_layers, gpt_results['curvatures'])\n",
        "\n",
        "        # Interpolate cumulative lengths\n",
        "        llama_length_interp = np.interp(layer_range, llama_layers, llama_results['cumulative_length'])\n",
        "        gpt_length_interp = np.interp(layer_range, gpt_layers, gpt_results['cumulative_length'])\n",
        "\n",
        "        # Create smooth surface\n",
        "        curvature_surface = np.outer(1 - model_range, llama_interp) + np.outer(model_range, gpt_interp)\n",
        "        length_surface = np.outer(1 - model_range, llama_length_interp) + np.outer(model_range, gpt_length_interp)\n",
        "\n",
        "        fig.add_trace(go.Surface(\n",
        "            x=layer_grid,\n",
        "            y=curvature_surface,\n",
        "            z=length_surface,\n",
        "            colorscale='Viridis',\n",
        "            opacity=0.4,\n",
        "            showscale=False,\n",
        "            name='Interpolated Surface',\n",
        "            hovertemplate='Layer: %{x:.0f}<br>Curvature: %{y:.4f}<br>Length: %{z:.4f}<extra></extra>'\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        # Update 3D axes with proper labels\n",
        "        fig.update_scenes(\n",
        "            xaxis=dict(\n",
        "                title=\"<b>Layer Depth (Network Position)</b>\",\n",
        "                backgroundcolor=\"rgb(230, 230,230)\",\n",
        "                gridcolor=\"white\",\n",
        "                showbackground=True\n",
        "            ),\n",
        "            yaxis=dict(\n",
        "                title=\"<b>Spectral Curvature Îº</b>\",\n",
        "                backgroundcolor=\"rgb(230, 230,230)\",\n",
        "                gridcolor=\"white\",\n",
        "                showbackground=True\n",
        "            ),\n",
        "            zaxis=dict(\n",
        "                title=\"<b>Cumulative Thermodynamic Length L</b>\",\n",
        "                backgroundcolor=\"rgb(230, 230,230)\",\n",
        "                gridcolor=\"white\",\n",
        "                showbackground=True\n",
        "            ),\n",
        "            camera=dict(\n",
        "                eye=dict(x=1.5, y=1.5, z=1.3)\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # ==== PLOT 2: Cumulative Length ====\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=llama_layers,\n",
        "            y=llama_results['cumulative_length'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='blue', width=3),\n",
        "            marker=dict(size=8, color='lightblue'),\n",
        "            name='Llama-3.2',\n",
        "            hovertemplate='Layer: %{x}<br>Cumulative Length: %{y:.4f}<extra></extra>'\n",
        "        ), row=2, col=1)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=gpt_layers,\n",
        "            y=gpt_results['cumulative_length'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='red', width=3),\n",
        "            marker=dict(size=8, color='lightcoral'),\n",
        "            name='GPT-2 Large',\n",
        "            hovertemplate='Layer: %{x}<br>Cumulative Length: %{y:.4f}<extra></extra>'\n",
        "        ), row=2, col=1)\n",
        "\n",
        "        fig.update_xaxes(title_text=\"<b>Layer Index (Depth)</b>\", row=2, col=1)\n",
        "        fig.update_yaxes(title_text=\"<b>Cumulative Thermodynamic Length</b>\", row=2, col=1)\n",
        "\n",
        "        # ==== PLOT 3: Spectral Curvature Evolution ====\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=llama_layers,\n",
        "            y=llama_results['curvatures'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='blue', width=3),\n",
        "            marker=dict(size=8),\n",
        "            name='Llama-3.2',\n",
        "            hovertemplate='Layer: %{x}<br>Curvature: %{y:.4f}<extra></extra>'\n",
        "        ), row=2, col=2)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=gpt_layers,\n",
        "            y=gpt_results['curvatures'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='red', width=3),\n",
        "            marker=dict(size=8),\n",
        "            name='GPT-2 Large',\n",
        "            hovertemplate='Layer: %{x}<br>Curvature: %{y:.4f}<extra></extra>'\n",
        "        ), row=2, col=2)\n",
        "\n",
        "        fig.update_xaxes(title_text=\"<b>Layer Index (Depth)</b>\", row=2, col=2)\n",
        "        fig.update_yaxes(title_text=\"<b>Spectral Curvature Îº</b>\", row=2, col=2)\n",
        "\n",
        "        # ==== PLOT 4: Layer Contributions ====\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=llama_layers,\n",
        "            y=llama_results['layer_contributions'],\n",
        "            mode='lines+markers',\n",
        "            fill='tozeroy',\n",
        "            line=dict(color='blue', width=2),\n",
        "            marker=dict(size=6),\n",
        "            name='Llama-3.2',\n",
        "            hovertemplate='Layer: %{x}<br>Contribution: %{y:.4f}<extra></extra>'\n",
        "        ), row=3, col=1)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=gpt_layers,\n",
        "            y=gpt_results['layer_contributions'],\n",
        "            mode='lines+markers',\n",
        "            fill='tozeroy',\n",
        "            line=dict(color='red', width=2),\n",
        "            marker=dict(size=6),\n",
        "            name='GPT-2 Large',\n",
        "            hovertemplate='Layer: %{x}<br>Contribution: %{y:.4f}<extra></extra>'\n",
        "        ), row=3, col=1)\n",
        "\n",
        "        fig.update_xaxes(title_text=\"<b>Layer Index (Depth)</b>\", row=3, col=1)\n",
        "        fig.update_yaxes(title_text=\"<b>Layer Contribution to Length</b>\", row=3, col=1)\n",
        "\n",
        "        # ==== PLOT 5: Total Length Comparison ====\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=['Llama-3.2-3B', 'GPT-2 Large'],\n",
        "            y=[llama_results['total_length'], gpt_results['total_length']],\n",
        "            marker=dict(\n",
        "                color=['blue', 'red'],\n",
        "                line=dict(color='black', width=2)\n",
        "            ),\n",
        "            text=[f\"{llama_results['total_length']:.4f}\",\n",
        "                  f\"{gpt_results['total_length']:.4f}\"],\n",
        "            textposition='outside',\n",
        "            hovertemplate='<b>%{x}</b><br>Total Length: %{y:.6f}<extra></extra>'\n",
        "        ), row=3, col=2)\n",
        "\n",
        "        # Update axis labels for Plot 5\n",
        "        fig.update_xaxes(title_text=\"<b>Model</b>\", row=3, col=2)\n",
        "        fig.update_yaxes(title_text=\"<b>Total Thermodynamic Length</b>\", row=3, col=2)\n",
        "\n",
        "\n",
        "        # Overall layout\n",
        "        fig.update_layout(\n",
        "            title=dict(\n",
        "                text=(\n",
        "                    '<b>Thermodynamic Length Analysis via Spectral Curvature (Method 2)</b><br>' +\n",
        "                    '<sub>Llama-3.2-3B vs GPT-2 Large on SQuAD 2.0 | Fisher-Rao Metric</sub>'\n",
        "                ),\n",
        "                x=0.5,\n",
        "                xanchor='center',\n",
        "                font=dict(size=18)\n",
        "            ),\n",
        "            height=1400,\n",
        "            width=1600,\n",
        "            showlegend=True,\n",
        "            legend=dict(x=0.02, y=0.98),\n",
        "            template='plotly_white'\n",
        "        )\n",
        "\n",
        "        fig.show()\n",
        "        return fig\n",
        "\n",
        "def run_thermodynamic_analysis():\n",
        "    \"\"\"Main execution\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Initialize\n",
        "    analyzer = ThermodynamicLengthAnalyzer()\n",
        "\n",
        "    # Load models and data\n",
        "    models = analyzer.load_models()\n",
        "    samples = analyzer.load_squad_v2()\n",
        "\n",
        "    # Analyze both models\n",
        "    llama_results = analyzer.analyze_model_complete(\n",
        "        models['llama'], models['llama_tok'], samples, \"Llama-3.2-3B\"\n",
        "    )\n",
        "\n",
        "    gpt_results = analyzer.analyze_model_complete(\n",
        "        models['gpt'], models['gpt_tok'], samples, \"GPT-2 Large\"\n",
        "    )\n",
        "\n",
        "    # Create plots\n",
        "    fig = analyzer.create_publication_quality_plots(llama_results, gpt_results)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ðŸ† FINAL RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nðŸ“Š LLAMA-3.2-3B:\")\n",
        "    print(f\"   Layers: {llama_results['num_layers']}\")\n",
        "    print(f\"   Total Thermodynamic Length: {llama_results['total_length']:.6f}\")\n",
        "    print(f\"   Avg Spectral Curvature: {np.mean(llama_results['curvatures']):.4f}\")\n",
        "    print(f\"   Max Layer Contribution: {np.max(llama_results['layer_contributions']):.4f}\")\n",
        "\n",
        "    print(f\"\\nðŸ“Š GPT-2 LARGE:\")\n",
        "    print(f\"   Layers: {gpt_results['num_layers']}\")\n",
        "    print(f\"   Total Thermodynamic Length: {gpt_results['total_length']:.6f}\")\n",
        "    print(f\"   Avg Spectral Curvature: {np.mean(gpt_results['curvatures']):.4f}\")\n",
        "    print(f\"   Max Layer Contribution: {np.max(gpt_results['layer_contributions']):.4f}\")\n",
        "\n",
        "    winner = \"Llama-3.2\" if llama_results['total_length'] > gpt_results['total_length'] else \"GPT-2\"\n",
        "    diff = abs(llama_results['total_length'] - gpt_results['total_length'])\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ COMPARISON:\")\n",
        "    print(f\"   Winner (Higher Complexity): {winner}\")\n",
        "    print(f\"   Absolute Difference: {diff:.6f}\")\n",
        "    print(f\"   Relative Difference: {(diff/min(llama_results['total_length'], gpt_results['total_length'])*100):.2f}%\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    return {\n",
        "        'llama': llama_results,\n",
        "        'gpt': gpt_results,\n",
        "        'figure': fig\n",
        "    }\n",
        "\n",
        "# Execute\n",
        "results = run_thermodynamic_analysis()"
      ],
      "metadata": {
        "id": "O7DVZGSGEbS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama-3.2-3B on SQuAD 2.0 -- module prototype"
      ],
      "metadata": {
        "id": "_nMJOr_Yithg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets plotly torch\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class RobustThermodynamicLength:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(\"ROBUST THERMODYNAMIC LENGTH - NO NAN GUARANTEED\")\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Load models without NaN issues\"\"\"\n",
        "        print(\"\\nLoading models...\")\n",
        "\n",
        "        # GPT-2 Large\n",
        "        self.gpt_tok = AutoTokenizer.from_pretrained(\"gpt2-large\")\n",
        "        self.gpt_tok.pad_token = self.gpt_tok.eos_token\n",
        "        self.gpt_model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"gpt2-large\", torch_dtype=torch.float16, device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        # Get layer count for GPT-2\n",
        "        if hasattr(self.gpt_model, 'transformer') and hasattr(self.gpt_model.transformer, 'h'):\n",
        "            self.gpt_layers = len(self.gpt_model.transformer.h)\n",
        "        else:\n",
        "            self.gpt_layers = 36  # Default for gpt2-large\n",
        "\n",
        "        # Llama-3.2 or fallback\n",
        "        try:\n",
        "            self.llama_tok = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
        "            self.llama_tok.pad_token = self.llama_tok.eos_token\n",
        "            self.llama_model = AutoModelForCausalLM.from_pretrained(\n",
        "                \"meta-llama/Llama-3.2-3B\", torch_dtype=torch.float16, device_map=\"auto\"\n",
        "            )\n",
        "            self.llama_name = \"Llama-3.2\"\n",
        "        except:\n",
        "            print(\"Using GPT2-medium as Llama proxy\")\n",
        "            self.llama_tok = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
        "            self.llama_tok.pad_token = self.llama_tok.eos_token\n",
        "            self.llama_model = AutoModelForCausalLM.from_pretrained(\n",
        "                \"gpt2-medium\", torch_dtype=torch.float16, device_map=\"auto\"\n",
        "            )\n",
        "            self.llama_name = \"GPT2-Medium (proxy)\"\n",
        "\n",
        "        # Get layer count for Llama\n",
        "        if hasattr(self.llama_model, 'transformer') and hasattr(self.llama_model.transformer, 'h'):\n",
        "            self.llama_layers = len(self.llama_model.transformer.h)\n",
        "        elif hasattr(self.llama_model, 'model') and hasattr(self.llama_model.model, 'layers'):\n",
        "            self.llama_layers = len(self.llama_model.model.layers)\n",
        "        else:\n",
        "            self.llama_layers = 24  # Default fallback\n",
        "\n",
        "        print(f\"âœ“ GPT-2 Large: {self.gpt_layers} layers\")\n",
        "        print(f\"âœ“ {self.llama_name}: {self.llama_layers} layers\")\n",
        "\n",
        "        torch.cuda.empty_cache()  # Clear cache\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load SQuAD 2.0 samples\"\"\"\n",
        "        print(\"\\nLoading SQuAD 2.0...\")\n",
        "        ds = load_dataset(\"squad_v2\", split=\"validation[:15]\")\n",
        "\n",
        "        self.samples = []\n",
        "        for item in ds:\n",
        "            context = item['context'][:200]  # Truncate for efficiency\n",
        "            question = item['question']\n",
        "            text = f\"Question: {question}\\nContext: {context}\"\n",
        "            self.samples.append(text)\n",
        "\n",
        "        print(f\"âœ“ Loaded {len(self.samples)} samples\")\n",
        "\n",
        "    def robust_fisher_information(self, hidden_state):\n",
        "        \"\"\"\n",
        "        Compute Fisher Information with guaranteed no NaN\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Handle dimensions\n",
        "            if hidden_state.dim() == 3:\n",
        "                hidden_state = hidden_state.squeeze(0)\n",
        "\n",
        "            # Replace any NaN/Inf values\n",
        "            hidden_state = torch.nan_to_num(hidden_state, nan=0.0, posinf=1e5, neginf=-1e5)\n",
        "\n",
        "            # Basic check - if too small, return default\n",
        "            if hidden_state.shape[0] < 2 or hidden_state.shape[1] < 2:\n",
        "                return 1.0\n",
        "\n",
        "            # Center the data\n",
        "            mean = hidden_state.mean(dim=0, keepdim=True)\n",
        "            centered = hidden_state - mean\n",
        "\n",
        "            # Strong regularization for stability\n",
        "            n = centered.shape[0]\n",
        "            reg_strength = 1e-4 * torch.max(torch.abs(centered)).item()\n",
        "\n",
        "            # Compute Fisher Information Matrix (covariance)\n",
        "            fisher_matrix = torch.matmul(centered.T, centered) / max(n - 1, 1)\n",
        "\n",
        "            # Add regularization\n",
        "            eye_tensor = torch.eye(fisher_matrix.shape[0], device=fisher_matrix.device)\n",
        "            fisher_matrix = fisher_matrix + reg_strength * eye_tensor\n",
        "\n",
        "            # Use Frobenius norm as scalar measure\n",
        "            fisher_norm = torch.norm(fisher_matrix, p='fro').item()\n",
        "\n",
        "            # Final NaN check\n",
        "            if np.isnan(fisher_norm) or np.isinf(fisher_norm):\n",
        "                return 1.0\n",
        "\n",
        "            return max(fisher_norm, 1e-6)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: {e}, returning default value\")\n",
        "            return 1.0\n",
        "\n",
        "    def safe_fisher_rao(self, f1, f2):\n",
        "        \"\"\"\n",
        "        Compute Fisher-Rao distance with guaranteed no NaN\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ensure positive values\n",
        "            f1 = max(abs(float(f1)), 1e-6)\n",
        "            f2 = max(abs(float(f2)), 1e-6)\n",
        "\n",
        "            # Handle edge cases explicitly\n",
        "            if abs(f1 - f2) < 1e-10:\n",
        "                return 0.0\n",
        "\n",
        "            # Compute with extreme caution\n",
        "            sqrt_product = np.sqrt(f1 * f2)\n",
        "            sum_values = f1 + f2\n",
        "\n",
        "            # Super safe ratio calculation\n",
        "            if sum_values < 1e-10:\n",
        "                return 0.0\n",
        "\n",
        "            ratio = sqrt_product / sum_values\n",
        "\n",
        "            # Ensure valid arccos input\n",
        "            ratio = np.clip(ratio, 0.0, 0.9999)\n",
        "\n",
        "            # Calculate distance\n",
        "            distance = 2.0 * np.arccos(ratio)\n",
        "\n",
        "            # Final validation\n",
        "            if np.isnan(distance) or np.isinf(distance):\n",
        "                return 0.0\n",
        "\n",
        "            return float(distance)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning in distance: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def analyze_model(self, model, tokenizer, name, num_layers):\n",
        "        \"\"\"\n",
        "        Compute thermodynamic length for a model\n",
        "        \"\"\"\n",
        "        print(f\"\\nAnalyzing {name}...\")\n",
        "\n",
        "        # Storage for results\n",
        "        all_fisher_values = []\n",
        "\n",
        "        # Process samples (limit to 6 for efficiency)\n",
        "        for idx, text in enumerate(self.samples[:6]):\n",
        "            try:\n",
        "                # Tokenize\n",
        "                inputs = tokenizer(\n",
        "                    text, return_tensors=\"pt\", max_length=200,\n",
        "                    padding=True, truncation=True\n",
        "                ).to(self.device)\n",
        "\n",
        "                # Get hidden states\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(**inputs, output_hidden_states=True)\n",
        "\n",
        "                # Extract and process hidden states\n",
        "                hidden_states = outputs.hidden_states\n",
        "\n",
        "                # Compute Fisher information\n",
        "                layer_fisher = []\n",
        "                for i in range(min(len(hidden_states), num_layers + 1)):\n",
        "                    fisher = self.robust_fisher_information(hidden_states[i])\n",
        "                    layer_fisher.append(fisher)\n",
        "\n",
        "                all_fisher_values.append(layer_fisher)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sample {idx}: {e}\")\n",
        "                # Add a dummy entry if we failed\n",
        "                all_fisher_values.append([1.0] * (num_layers + 1))\n",
        "\n",
        "            # Progress update\n",
        "            if (idx + 1) % 2 == 0:\n",
        "                print(f\"  Processed {idx+1}/{min(len(self.samples), 6)} samples\")\n",
        "\n",
        "        # Average and ensure no NaN\n",
        "        if len(all_fisher_values) == 0:\n",
        "            print(\"âš ï¸ No valid samples processed!\")\n",
        "            # Return dummy values\n",
        "            fisher_avg = np.ones(num_layers + 1)\n",
        "            distances = np.zeros(num_layers + 1)\n",
        "            cumulative = np.zeros(num_layers + 1)\n",
        "            return {\n",
        "                'name': name, 'layers': num_layers,\n",
        "                'fisher': fisher_avg, 'distances': distances,\n",
        "                'cumulative': cumulative, 'total': 0.0\n",
        "            }\n",
        "\n",
        "        # Ensure consistent length\n",
        "        max_len = max(len(x) for x in all_fisher_values)\n",
        "        for i in range(len(all_fisher_values)):\n",
        "            if len(all_fisher_values[i]) < max_len:\n",
        "                # Pad with last value\n",
        "                last_val = all_fisher_values[i][-1] if all_fisher_values[i] else 1.0\n",
        "                all_fisher_values[i] = all_fisher_values[i] + [last_val] * (max_len - len(all_fisher_values[i]))\n",
        "\n",
        "        # Average across samples with NaN protection\n",
        "        fisher_avg = np.nanmean(all_fisher_values, axis=0)\n",
        "        fisher_avg = np.nan_to_num(fisher_avg, nan=1.0)\n",
        "        fisher_avg = np.maximum(fisher_avg, 1e-6)  # Ensure minimum value\n",
        "\n",
        "        # Compute distances\n",
        "        distances = [0.0]  # First layer has zero distance\n",
        "        for i in range(1, len(fisher_avg)):\n",
        "            d = self.safe_fisher_rao(fisher_avg[i-1], fisher_avg[i])\n",
        "            distances.append(float(d))\n",
        "\n",
        "        # Convert to numpy array with NaN protection\n",
        "        distances = np.array(distances)\n",
        "        distances = np.nan_to_num(distances, nan=0.0)\n",
        "\n",
        "        # Compute cumulative length\n",
        "        cumulative = np.cumsum(distances)\n",
        "        total_length = float(cumulative[-1])\n",
        "\n",
        "        print(f\"  âœ“ Total Thermodynamic Length: {total_length:.4f}\")\n",
        "\n",
        "        return {\n",
        "            'name': name,\n",
        "            'layers': num_layers,\n",
        "            'fisher': fisher_avg,\n",
        "            'distances': distances,\n",
        "            'cumulative': cumulative,\n",
        "            'total': total_length\n",
        "        }\n",
        "\n",
        "    def create_plots(self, llama_results, gpt_results):\n",
        "        \"\"\"Create publication-quality plots\"\"\"\n",
        "        print(\"\\nCreating visualizations...\")\n",
        "\n",
        "        # Create figure with subplots\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            specs=[\n",
        "                [{\"type\": \"scatter3d\", \"colspan\": 2}, None],\n",
        "                [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]\n",
        "            ],\n",
        "            subplot_titles=[\n",
        "                \"3D Thermodynamic Trajectory\",\n",
        "                \"Cumulative Length Evolution by Layer\",\n",
        "                \"Total Thermodynamic Length Comparison\"\n",
        "            ],\n",
        "            vertical_spacing=0.15,\n",
        "            row_heights=[0.7, 0.3]\n",
        "        )\n",
        "\n",
        "        # Layer indices\n",
        "        llama_x = np.arange(len(llama_results['fisher']))\n",
        "        gpt_x = np.arange(len(gpt_results['fisher']))\n",
        "\n",
        "        # 3D PLOT - Llama trajectory\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=llama_x,\n",
        "            y=llama_results['fisher'],\n",
        "            z=llama_results['cumulative'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='blue', width=6),\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                color=llama_results['cumulative'],\n",
        "                colorscale='Blues',\n",
        "                showscale=True,\n",
        "                colorbar=dict(\n",
        "                    title=\"Cumulative<br>Length\",\n",
        "                    x=1.02,\n",
        "                    len=0.4,\n",
        "                    y=0.8\n",
        "                )\n",
        "            ),\n",
        "            name=llama_results['name'],\n",
        "            hovertemplate=(\n",
        "                '<b>%{text}</b><br>' +\n",
        "                'Layer: %{x}<br>' +\n",
        "                'Fisher Info: %{y:.2f}<br>' +\n",
        "                'Length: %{z:.4f}<br>' +\n",
        "                '<extra></extra>'\n",
        "            ),\n",
        "            text=[f\"{llama_results['name']} Layer {i}\" for i in llama_x]\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        # 3D PLOT - GPT trajectory\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=gpt_x,\n",
        "            y=gpt_results['fisher'],\n",
        "            z=gpt_results['cumulative'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='red', width=6),\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                color=gpt_results['cumulative'],\n",
        "                colorscale='Reds',\n",
        "                showscale=True,\n",
        "                colorbar=dict(\n",
        "                    title=\"Cumulative<br>Length\",\n",
        "                    x=1.10,\n",
        "                    len=0.4,\n",
        "                    y=0.8\n",
        "                )\n",
        "            ),\n",
        "            name=\"GPT-2 Large\",\n",
        "            hovertemplate=(\n",
        "                '<b>GPT-2 Layer %{x}</b><br>' +\n",
        "                'Fisher Info: %{y:.2f}<br>' +\n",
        "                'Length: %{z:.4f}<br>' +\n",
        "                '<extra></extra>'\n",
        "            )\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        # Create safe interpolation grid\n",
        "        common_length = min(30, max(len(llama_x), len(gpt_x)))\n",
        "\n",
        "        # Forced length to avoid errors\n",
        "        llama_x_grid = np.linspace(0, len(llama_x)-1, common_length)\n",
        "        gpt_x_grid = np.linspace(0, len(gpt_x)-1, common_length)\n",
        "\n",
        "        # Safe interpolation\n",
        "        llama_fisher = np.interp(llama_x_grid, np.arange(len(llama_results['fisher'])), llama_results['fisher'])\n",
        "        llama_cumul = np.interp(llama_x_grid, np.arange(len(llama_results['cumulative'])), llama_results['cumulative'])\n",
        "\n",
        "        gpt_fisher = np.interp(gpt_x_grid, np.arange(len(gpt_results['fisher'])), gpt_results['fisher'])\n",
        "        gpt_cumul = np.interp(gpt_x_grid, np.arange(len(gpt_results['cumulative'])), gpt_results['cumulative'])\n",
        "\n",
        "        # Create surface grid\n",
        "        grid_x = np.linspace(0, common_length-1, common_length)\n",
        "        grid_y = np.linspace(0, 1, 20)\n",
        "        X, Y = np.meshgrid(grid_x, grid_y)\n",
        "\n",
        "        # Create surface values\n",
        "        Z_fisher = np.zeros_like(X)\n",
        "        Z_cumul = np.zeros_like(X)\n",
        "\n",
        "        for i, t in enumerate(grid_y):\n",
        "            Z_fisher[i, :] = (1 - t) * llama_fisher + t * gpt_fisher\n",
        "            Z_cumul[i, :] = (1 - t) * llama_cumul + t * gpt_cumul\n",
        "\n",
        "        # Add surface\n",
        "        fig.add_trace(go.Surface(\n",
        "            x=X,\n",
        "            y=Z_fisher,\n",
        "            z=Z_cumul,\n",
        "            colorscale='Viridis',\n",
        "            opacity=0.7,\n",
        "            showscale=False\n",
        "        ), row=1, col=1)\n",
        "\n",
        "        # Label 3D axes\n",
        "        fig.update_scenes(\n",
        "            xaxis_title=\"<b>Layer Depth</b>\",\n",
        "            yaxis_title=\"<b>Fisher Information</b>\",\n",
        "            zaxis_title=\"<b>Cumulative Length</b>\",\n",
        "            camera=dict(eye=dict(x=1.5, y=1.5, z=1.2)),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Line plot - Cumulative length\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=llama_x,\n",
        "            y=llama_results['cumulative'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='blue', width=3),\n",
        "            marker=dict(size=6),\n",
        "            name=llama_results['name']\n",
        "        ), row=2, col=1)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=gpt_x,\n",
        "            y=gpt_results['cumulative'],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color='red', width=3),\n",
        "            marker=dict(size=6),\n",
        "            name='GPT-2 Large'\n",
        "        ), row=2, col=1)\n",
        "\n",
        "        fig.update_xaxes(title_text=\"<b>Layer Index</b>\", row=2, col=1)\n",
        "        fig.update_yaxes(title_text=\"<b>Cumulative Length</b>\", row=2, col=1)\n",
        "\n",
        "        # Bar chart - Total length\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=[llama_results['name'], 'GPT-2 Large'],\n",
        "            y=[llama_results['total'], gpt_results['total']],\n",
        "            marker=dict(color=['blue', 'red']),\n",
        "            text=[f\"{llama_results['total']:.4f}\", f\"{gpt_results['total']:.4f}\"],\n",
        "            textposition='outside'\n",
        "        ), row=2, col=2)\n",
        "\n",
        "        fig.update_xaxes(title_text=\"<b>Model</b>\", row=2, col=2)\n",
        "        fig.update_yaxes(title_text=\"<b>Total Length</b>\", row=2, col=2)\n",
        "\n",
        "        # Layout\n",
        "        fig.update_layout(\n",
        "            title=\"<b>Thermodynamic Length Analysis - Method 2</b><br><sup>Fisher-Rao Metric on SQuAD 2.0</sup>\",\n",
        "            height=800,\n",
        "            width=1000,\n",
        "            showlegend=True\n",
        "        )\n",
        "\n",
        "        fig.show()\n",
        "        return fig\n",
        "\n",
        "# Main execution\n",
        "def run_robust_analysis():\n",
        "    # Initialize\n",
        "    analyzer = RobustThermodynamicLength()\n",
        "    analyzer.load_models()\n",
        "    analyzer.load_data()\n",
        "\n",
        "    # Analyze models\n",
        "    llama_results = analyzer.analyze_model(\n",
        "        analyzer.llama_model, analyzer.llama_tok,\n",
        "        analyzer.llama_name, analyzer.llama_layers\n",
        "    )\n",
        "\n",
        "    gpt_results = analyzer.analyze_model(\n",
        "        analyzer.gpt_model, analyzer.gpt_tok,\n",
        "        \"GPT-2 Large\", analyzer.gpt_layers\n",
        "    )\n",
        "\n",
        "    # Create plots\n",
        "    fig = analyzer.create_plots(llama_results, gpt_results)\n",
        "\n",
        "    # Final results\n",
        "    print(\"\\n===== FINAL RESULTS =====\")\n",
        "    print(f\"{llama_results['name']}: {llama_results['total']:.6f}\")\n",
        "    print(f\"GPT-2 Large: {gpt_results['total']:.6f}\")\n",
        "\n",
        "    winner = llama_results['name'] if llama_results['total'] > gpt_results['total'] else \"GPT-2 Large\"\n",
        "    print(f\"Higher thermodynamic complexity: {winner}\")\n",
        "    print(\"=========================\")\n",
        "\n",
        "# Run analysis\n",
        "run_robust_analysis()"
      ],
      "metadata": {
        "id": "n386Hr24RTeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thermodynamic Length Analysis for Llama-3.2-3B -- another varient"
      ],
      "metadata": {
        "id": "eCYboopYjDIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets torch matplotlib seaborn\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Force matplotlib to work in Colab\n",
        "plt.style.use('default')\n",
        "%matplotlib inline\n",
        "\n",
        "class WorkingThermodynamics:\n",
        "    def __init__(self):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"Device: {self.device}\")\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load model with fallback\"\"\"\n",
        "        try:\n",
        "            print(\"Loading Llama-3.2-3B...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                \"meta-llama/Llama-3.2-3B\",\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True\n",
        "            ).eval()\n",
        "            self.layers = len(self.model.model.layers)\n",
        "            self.model_name = \"Llama-3.2-3B\"\n",
        "            print(f\"âœ“ Loaded {self.model_name}: {self.layers} layers\")\n",
        "        except:\n",
        "            print(\"Loading GPT2-medium fallback...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                \"gpt2-medium\", torch_dtype=torch.float16, device_map=\"auto\"\n",
        "            ).eval()\n",
        "            self.layers = len(self.model.transformer.h)\n",
        "            self.model_name = \"GPT2-Medium\"\n",
        "            print(f\"âœ“ Loaded {self.model_name}: {self.layers} layers\")\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load SQuAD data\"\"\"\n",
        "        print(\"Loading SQuAD 2.0...\")\n",
        "        ds = load_dataset(\"squad_v2\", split=\"validation[:8]\")\n",
        "        self.texts = [f\"Q: {d['question']}\\nC: {d['context'][:150]}\" for d in ds]\n",
        "        print(f\"âœ“ {len(self.texts)} samples loaded\")\n",
        "\n",
        "    def compute_measure(self, hidden):\n",
        "        \"\"\"Compute thermodynamic measure\"\"\"\n",
        "        if hidden.dim() == 3:\n",
        "            hidden = hidden.squeeze(0)\n",
        "        hidden = torch.nan_to_num(hidden, 0.0)\n",
        "\n",
        "        if hidden.shape[0] < 2:\n",
        "            return 1.0\n",
        "\n",
        "        # Simple covariance trace\n",
        "        centered = hidden - hidden.mean(0, keepdim=True)\n",
        "        cov = torch.matmul(centered.T, centered) / (centered.shape[0] - 1)\n",
        "        measure = torch.trace(cov).item()\n",
        "        return max(measure, 1e-6)\n",
        "\n",
        "    def analyze(self):\n",
        "        \"\"\"Main analysis\"\"\"\n",
        "        print(\"Analyzing all layers...\")\n",
        "        all_measures = []\n",
        "\n",
        "        for i, text in enumerate(self.texts):\n",
        "            tokens = self.tokenizer(text, return_tensors=\"pt\", max_length=100,\n",
        "                                  truncation=True, padding=True).to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                out = self.model(**tokens, output_hidden_states=True)\n",
        "\n",
        "            measures = [self.compute_measure(h) for h in out.hidden_states]\n",
        "            all_measures.append(measures)\n",
        "            print(f\"  Sample {i+1}/{len(self.texts)} done\")\n",
        "\n",
        "        # Average and compute distances\n",
        "        self.measures = np.mean(all_measures, axis=0)\n",
        "        self.measures = np.nan_to_num(self.measures, 1.0)\n",
        "\n",
        "        # Simple distance calculation\n",
        "        self.distances = [0.0]\n",
        "        for i in range(1, len(self.measures)):\n",
        "            dist = abs(np.log(max(self.measures[i], 1e-6)) - np.log(max(self.measures[i-1], 1e-6)))\n",
        "            self.distances.append(dist)\n",
        "\n",
        "        self.distances = np.array(self.distances)\n",
        "        self.cumulative = np.cumsum(self.distances)\n",
        "        self.total = self.cumulative[-1]\n",
        "\n",
        "        print(f\"âœ“ Total thermodynamic length: {self.total:.4f}\")\n",
        "\n",
        "    def create_plots(self):\n",
        "        \"\"\"Create working matplotlib plots\"\"\"\n",
        "        print(\"Creating plots...\")\n",
        "\n",
        "        layers = np.arange(len(self.measures))\n",
        "\n",
        "        # Create figure with subplots\n",
        "        fig = plt.figure(figsize=(16, 12))\n",
        "\n",
        "        # Plot 1: 3D-like plot using matplotlib\n",
        "        ax1 = plt.subplot(2, 3, 1, projection='3d')\n",
        "        ax1.plot(layers, self.measures, self.cumulative, 'bo-', linewidth=2, markersize=6)\n",
        "        ax1.set_xlabel('Layer Depth')\n",
        "        ax1.set_ylabel('Thermodynamic Measure')\n",
        "        ax1.set_zlabel('Cumulative Length')\n",
        "        ax1.set_title('3D Thermodynamic Trajectory')\n",
        "\n",
        "        # Plot 2: Measures by layer\n",
        "        ax2 = plt.subplot(2, 3, 2)\n",
        "        ax2.plot(layers, self.measures, 'bo-', linewidth=2, markersize=6)\n",
        "        ax2.fill_between(layers, self.measures, alpha=0.3)\n",
        "        ax2.set_xlabel('Layer Depth')\n",
        "        ax2.set_ylabel('Thermodynamic Measure')\n",
        "        ax2.set_title('Layer-wise Measures')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 3: Cumulative length\n",
        "        ax3 = plt.subplot(2, 3, 3)\n",
        "        ax3.plot(layers, self.cumulative, 'ro-', linewidth=2, markersize=6)\n",
        "        ax3.fill_between(layers, self.cumulative, alpha=0.3, color='red')\n",
        "        ax3.set_xlabel('Layer Depth')\n",
        "        ax3.set_ylabel('Cumulative Length')\n",
        "        ax3.set_title('Cumulative Growth')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 4: Distance contributions\n",
        "        ax4 = plt.subplot(2, 3, 4)\n",
        "        bars = ax4.bar(layers, self.distances, alpha=0.7, color='green')\n",
        "        ax4.set_xlabel('Layer Depth')\n",
        "        ax4.set_ylabel('Distance Contribution')\n",
        "        ax4.set_title('Layer Contributions')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 5: Combined view\n",
        "        ax5 = plt.subplot(2, 3, 5)\n",
        "        ax5_twin = ax5.twinx()\n",
        "        line1 = ax5.plot(layers, self.measures, 'b-', linewidth=2, label='Measures')\n",
        "        line2 = ax5_twin.plot(layers, self.cumulative, 'r-', linewidth=2, label='Cumulative')\n",
        "        ax5.set_xlabel('Layer Depth')\n",
        "        ax5.set_ylabel('Measures', color='blue')\n",
        "        ax5_twin.set_ylabel('Cumulative', color='red')\n",
        "        ax5.set_title('Combined Analysis')\n",
        "        ax5.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 6: Heatmap\n",
        "        ax6 = plt.subplot(2, 3, 6)\n",
        "        # Normalize data for heatmap\n",
        "        norm_measures = self.measures / np.max(self.measures)\n",
        "        norm_distances = self.distances / np.max(self.distances) if np.max(self.distances) > 0 else self.distances\n",
        "        norm_cumulative = self.cumulative / np.max(self.cumulative)\n",
        "\n",
        "        heatmap_data = np.vstack([norm_measures, norm_distances, norm_cumulative])\n",
        "        im = ax6.imshow(heatmap_data, cmap='viridis', aspect='auto')\n",
        "        ax6.set_yticks([0, 1, 2])\n",
        "        ax6.set_yticklabels(['Measures', 'Distances', 'Cumulative'])\n",
        "        ax6.set_xlabel('Layer Index')\n",
        "        ax6.set_title('Analysis Heatmap')\n",
        "        plt.colorbar(im, ax=ax6)\n",
        "\n",
        "        plt.suptitle(f'Thermodynamic Length Analysis - {self.model_name}\\nTotal Length: {self.total:.6f}',\n",
        "                    fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Additional detailed plot\n",
        "        fig2, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "        # Detailed measures\n",
        "        axes[0,0].plot(layers, self.measures, 'o-', linewidth=3, markersize=8, color='purple')\n",
        "        axes[0,0].set_title('Thermodynamic Measures by Layer', fontsize=14, fontweight='bold')\n",
        "        axes[0,0].set_xlabel('Layer Depth')\n",
        "        axes[0,0].set_ylabel('Measure Value')\n",
        "        axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Detailed distances\n",
        "        axes[0,1].bar(layers, self.distances, color=plt.cm.plasma(layers/max(layers)), alpha=0.8)\n",
        "        axes[0,1].set_title('Distance Contributions by Layer', fontsize=14, fontweight='bold')\n",
        "        axes[0,1].set_xlabel('Layer Depth')\n",
        "        axes[0,1].set_ylabel('Distance')\n",
        "        axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Detailed cumulative\n",
        "        axes[1,0].plot(layers, self.cumulative, 's-', linewidth=3, markersize=8, color='orange')\n",
        "        axes[1,0].fill_between(layers, self.cumulative, alpha=0.3, color='orange')\n",
        "        axes[1,0].set_title('Cumulative Thermodynamic Length', fontsize=14, fontweight='bold')\n",
        "        axes[1,0].set_xlabel('Layer Depth')\n",
        "        axes[1,0].set_ylabel('Cumulative Length')\n",
        "        axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Rate of change\n",
        "        rate_change = np.gradient(self.cumulative)\n",
        "        axes[1,1].plot(layers, rate_change, '^-', linewidth=3, markersize=8, color='red')\n",
        "        axes[1,1].set_title('Rate of Length Change', fontsize=14, fontweight='bold')\n",
        "        axes[1,1].set_xlabel('Layer Depth')\n",
        "        axes[1,1].set_ylabel('Rate of Change')\n",
        "        axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.suptitle(f'Detailed Analysis - {self.model_name}', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Print detailed results\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"LAYER-BY-LAYER THERMODYNAMIC LENGTH RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"{'Layer':<8} {'Measure':<12} {'Distance':<12} {'Cumulative':<12}\")\n",
        "        print(\"-\"*60)\n",
        "\n",
        "        for i in range(len(self.measures)):\n",
        "            print(f\"{i:<8} {self.measures[i]:<12.6f} {self.distances[i]:<12.6f} {self.cumulative[i]:<12.6f}\")\n",
        "\n",
        "        print(\"-\"*60)\n",
        "        print(f\"Total Thermodynamic Length: {self.total:.8f}\")\n",
        "        print(f\"Number of Layers: {len(self.measures)}\")\n",
        "        print(f\"Model: {self.model_name}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"âœ… All plots created and displayed!\")\n",
        "\n",
        "# RUN ANALYSIS\n",
        "analyzer = WorkingThermodynamics()\n",
        "analyzer.load_model()\n",
        "analyzer.load_data()\n",
        "analyzer.analyze()\n",
        "analyzer.create_plots()"
      ],
      "metadata": {
        "id": "e8ykEHrbfGGX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}